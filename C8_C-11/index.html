<!doctype html><html lang="en"><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><title>Wabne - Class 8 - Computer Science - Chapter 11</title><link href="/style.css" rel="stylesheet"><script defer="defer" src="/script.js"></script><link href="/favicon.gif" rel="shortcut icon" type="image/x-icon"><nav><a href="/"><img alt="Logo" class="logo" src="/favicon.gif"></a><div class="title">Wabne</div><ul class="nav-menu"><li><a class="nav-link" href="/#home">Home</a></li><li><a class="nav-link" href="/#courses">Courses</a></li><li><a class="nav-link" href="/#about-us">About Us</a></li><li><a class="nav-link" href="/#choose-div">Why Us?</a></li></ul><div class="hamburger"><span class="bar"></span> <span class="bar"></span> <span class="bar"></span></div></nav><section class="chapter"><h1>Robotics</h1><img class="paspo" src="/robo1.png"><h2>Computing &amp; Languages in Robotics</h2><p>Robotics development uses a mix of languages and tools chosen for performance, ease of prototyping, hardware access, and ecosystem support. Common choices:</p><ul><li>Python — fast for prototyping, scripting, data processing, and working with machine learning libraries (TensorFlow, PyTorch).</li><li>C++ — used for performance-critical modules, low-latency control, and many robotics middleware libraries.</li><li>ROS / ROS2 (Robot Operating System) — framework, with nodes, topics, services, and actions; language bindings for C++ (roscpp) and Python (rospy / rclpy).</li><li>Embedded C (bare-metal) — microcontroller firmware for motor drivers, IMU sampling, and low-level control loops.</li><li>MATLAB / Simulink — simulation, control design, and model-based design workflows in academia and industry.</li><li>JavaScript / TypeScript — web UIs and cloud dashboards that interact with robots via web sockets and REST APIs.</li></ul><h3>Where each language is used — practical notes</h3><ul><li>Python: perception pipelines (OpenCV), data logging, quick control scripts, ML inference on embedded devices.</li><li>C++: real-time controllers, motion planning, kinematics libraries (MoveIt), sensor drivers (LiDAR, camera SDKs).</li><li>Embedded C: reading encoders, PWM motor control, sensor sampling loops, safety watchdogs.</li><li>ROS: glue between components — sensor publishers, controller subscribers, transform tree (tf/tf2), and bag files for recording.</li></ul><h2>Practical sensor &amp; actuator examples</h2><p>Below are concrete code examples you can run (or adapt) on robot hardware or simulators. These show reading a distance sensor, controlling a motor, and publishing to ROS.</p><computercode aria-label="Python distance sensor example" class="computercode" id="sensor_python" role="region"><button aria-label="Copy to clipboard" class="copy-btn" title="Copy" type="button">Copy</button><div class="code-content" spellcheck="false"># Python: read a HC-SR04-like ultrasonic sensor via GPIO (example for Raspberry Pi)<br>import time<br>import RPi.GPIO as GPIO<br><br>TRIG = 23<br>ECHO = 24<br><br>GPIO.setmode(GPIO.BCM)<br>GPIO.setup(TRIG, GPIO.OUT)<br>GPIO.setup(ECHO, GPIO.IN)<br><br>def read_distance_cm():<br>    GPIO.output(TRIG, False)<br>    time.sleep(0.0002)<br>    GPIO.output(TRIG, True)<br>    time.sleep(0.00001)<br>    GPIO.output(TRIG, False)<br><br>    start = time.time()<br>    while GPIO.input(ECHO) == 0:<br>        start = time.time()<br>    while GPIO.input(ECHO) == 1:<br>        stop = time.time()<br>    elapsed = stop - start<br>    distance = (elapsed * 34300) / 2  # speed of sound 34300 cm/s<br>    return distance<br><br>try:<br>    while True:<br>        d = read_distance_cm()<br>        print(f"Distance: {d:.1f} cm")<br>        time.sleep(0.2)<br>except KeyboardInterrupt:<br>    GPIO.cleanup()<br></div></computercode><computercode aria-label="Arduino motor PWM example" class="computercode" id="motor_pwm_arduino" role="region"><button aria-label="Copy to clipboard" class="copy-btn" title="Copy" type="button">Copy</button><div class="code-content" spellcheck="false">/* Arduino: simple PWM motor control using L298N or motor driver */<br>const int pwmPin = 5;    // PWM pin to motor driver EN<br>const int in1 = 7;    // direction pin 1<br>const int in2 = 8;    // direction pin 2<br><br>void setup() {<br>    pinMode(pwmPin, OUTPUT);<br>    pinMode(in1, OUTPUT);<br>    pinMode(in2, OUTPUT);<br>    analogWrite(pwmPin, 0);<br>}<br><br>void loop() {<br>    // Run forward<br>    digitalWrite(in1, HIGH);<br>    digitalWrite(in2, LOW);<br>    for (int speed = 0; speed &lt;= 200; speed += 10) {<br>        analogWrite(pwmPin, speed);<br>        delay(100);<br>    }<br>    delay(1000);<br>    // Stop<br>    analogWrite(pwmPin, 0);<br>    delay(500);<br>    // Run backward<br>    digitalWrite(in1, LOW);<br>    digitalWrite(in2, HIGH);<br>    analogWrite(pwmPin, 180);<br>    delay(1000);<br>    // Slow down<br>    analogWrite(pwmPin, 0);<br>    delay(2000);<br>}<br></div></computercode><computercode aria-label="ROS2 publisher example" class="computercode" id="ros_publisher_python" role="region"><button aria-label="Copy to clipboard" class="copy-btn" title="Copy" type="button">Copy</button><div class="code-content" spellcheck="false"># ROS2 (rclpy) example: publish distance sensor readings<br>import rclpy<br>from rclpy.node import Node<br>from sensor_msgs.msg import Range<br><br>class RangePublisher(Node):<br>    def __init__(self):<br>        super().__init__('range_publisher')<br>        self.pub = self.create_publisher(Range, 'sonar_range', 10)<br>        self.timer = self.create_timer(0.1, self.timer_callback)<br>        self.seq = 0<br><br>    def timer_callback(self):<br>        msg = Range()<br>        msg.header.stamp = self.get_clock().now().to_msg()<br>        msg.header.frame_id = 'sonar_link'<br>        msg.radiation_type = Range.ULTRASOUND<br>        msg.field_of_view = 0.5<br>        msg.min_range = 0.02<br>        msg.max_range = 4.0<br>        msg.range = read_distance_cm() / 100.0  # convert cm to meters<br>        self.pub.publish(msg)<br>        self.get_logger().info(f"Published range: {msg.range:.2f} m")<br><br>def main(args=None):<br>    rclpy.init(args=args)<br>    node = RangePublisher()<br>    rclpy.spin(node)<br>    node.destroy_node()<br>    rclpy.shutdown()<br><br>if __name__ == '__main__':<br>    main()<br></div></computercode><h2>Sensor fusion &amp; control loop example</h2><p>A practical robot will fuse IMU + encoder + vision to estimate pose, then run a control loop (PID or model predictive control). Below is pseudocode for a simple fusion loop and PID velocity control.</p><computercode aria-label="Fusion and PID pseudocode" class="computercode" id="fusion_pid" role="region"><button aria-label="Copy to clipboard" class="copy-btn" title="Copy" type="button">Copy</button><div class="code-content" spellcheck="false"># Pseudocode: sensor fusion (IMU + wheel odometry) and PID velocity control<br>state = {'x':0,'y':0,'theta':0, 'vx':0,'vy':0}<br>pid = PID(kp=1.0, ki=0.1, kd=0.01)<br><br>while True:<br>    imu = read_imu()                  // returns angular rates and linear accel<br>    odo = read_wheel_encoders() // returns delta ticks per wheel<br>    vision = read_vision_pose() // optional pose update from camera<br>    dt = compute_dt()<br>    odo_delta = odometry_from_encoders(odo, dt)<br>    # prediction step from IMU + odometry<br>    state = predict_state(state, imu, odo_delta, dt)<br>    if vision is not None:<br>        state = correct_state_with_vision(state, vision)<br>    # velocity control: compute required wheel commands<br>    desired_v = planner_next_velocity()<br>    error = desired_v - state['vx']<br>    ctrl = pid.update(error, dt)<br>    apply_motor_commands(ctrl)<br>    sleep(dt)<br></div></computercode><h2>Famous Robots</h2><h3>Rashmi</h3><img class="paspo" src="/rashmi.png"><p>Rashmi is a multilingual humanoid built for public engagement and education.<br>She uses a microphone array and beamforming to capture speech in noisy spaces.<br>Vision modules detect faces and pose so Rashmi can maintain polite eye contact.<br>Facial actuators (small servos) synchronize with speech to produce expressions.<br>Torso and arm motion use brushless motors with encoders for repeatable gestures.<br>A local dialog manager maps detected intents to scripted educational interactions.<br>Rashmi logs anonymized interaction metrics that teachers can review later.<br>Safety sensors (proximity ring, bump switches) stop motion if people get too close.<br>Maintenance focuses on actuator calibration, battery checks, and ASR model updates.<br>Rashmi demonstrates culturally aware robotics by combining speech, vision, and safe motion.</p><h3>Champak</h3><img class="paspo" src="/champk.png"><p>Champak is a child-focused storytelling and quiz robot for museums and classrooms.<br>Stereo cameras and simple pose estimation help Champak find and address its audience.<br>Directional audio and a DSP ensure clear playback without flooding the room with noise.<br>Micro-servo driven gestures synchronize with narration to make stories engaging.<br>Touch and proximity sensors let children interact directly and safely with the robot.<br>Content modules are stored locally and uploaded via a teacher-facing web UI.<br>Champak adapts question difficulty based on live quiz performance metrics.<br>Pressure sensors on the case trigger immediate soft-stops to prevent injury on contact.<br>Routine maintenance: check servos, update content packs, and refresh battery cycles.<br>Champak blends perception, safe actuation, and curriculum-driven interaction for learning.</p><h3>Mitra</h3><img class="paspo" src="/mitra.png"><p>Mitra is a service humanoid used for visitor guidance and basic assistance in public spaces.<br>She navigates with LiDAR-based SLAM plus short-range depth sensing for obstacle avoidance.<br>Face detection and optional embedding-based recognition enable personalized greetings (consent-based).<br>Position-controlled motors with torque sensing allow Mitra to gesture safely and reliably.<br>The software stack separates navigation, interaction, and safety with independent watchdogs.<br>Docking routines and scheduled charging keep Mitra available during peak hours.<br>Practical deployments include hospitals and corporate lobbies for wayfinding and FAQs.<br>Remote supervision tools let human operators intervene or teleoperate when needed.<br>Maintenance includes map cleanup, speech-model retraining, and regular sensor calibration.<br>Mitra shows how perception, enterprise APIs, and safe motion combine for useful service robots.</p><h3>RADA</h3><img class="paspo" src="/rada.png"><p>RADA assists customers in banks and offices with queue management and information delivery.<br>Interfaces include touchscreen menus, voice queries, and LED visual guidance for clarity.<br>Overhead or onboard cameras provide analytics for queue length and flow optimization.<br>RADA integrates with appointment systems to present anonymized schedules and suggestions.<br>Localization can use ORB-SLAM variants for branches that change layout frequently.<br>Safety features include soft bumpers, E-stop, and remote teleoperation fallback modes.<br>Operators monitor RADA via dashboards that report uptime, interactions, and error logs.<br>Updates to dialogues and UI modules are rolled out during off-peak windows to avoid downtime.<br>Operational metrics tracked: average wait reduction, user satisfaction, and service accuracy.<br>RADA demonstrates enterprise integration of robotics without exposing sensitive customer data.</p><h3>ASIMO</h3><img class="paspo" src="/asimo.png"><p>ASIMO is a pioneering bipedal humanoid developed for stable walking and human interaction.<br>Its gait relied on ZMP-based balance control with high-frequency joint feedback loops.<br>Sensors included encoders, IMUs, and stereo vision to perceive terrain and obstacles.<br>ASIMO demonstrated autonomous stair climbing with foot-placement planning and balance compensation.<br>Actuation used precision motors and gearings tuned for smooth multi-joint coordination.<br>High-level planning generated gestures and trajectories while low-level loops handled safety and tracking.<br>Maintenance involved frequent calibration of sensors and re-tuning gait parameters after wear.<br>ASIMO’s research contributions influenced later humanoid walking and whole-body planning work.<br>Public demos showed how mobility and social interaction can be combined safely on stage.<br>ASIMO remains a milestone in humanoid mechanics, control, and integrated sensing.</p><h3>Sophia</h3><img class="paspo" src="/sophia.png"><p>Sophia is a social humanoid known for expressive facial motion and conversational demos.<br>Micro-actuators beneath a flexible face material create nuanced eyebrow, lip, and cheek movements.<br>Vision and audio processing align gaze and speech timing for natural-feeling interactions.<br>Dialog systems mix rule-based safety layers with generative models for richer replies.<br>Moderation and guardrails are used to filter inappropriate or unsafe outputs in public talks.<br>Sophia’s design highlights mechanical expressivity combined with perception and language models.<br>Operational needs include actuator maintenance, model updates, and careful public moderation.<br>Sophia’s appearances often prompt public discussion about ethics, persona, and AI limits.<br>Her case emphasizes the importance of safety layers and content filtering in social robots.<br>Sophia demonstrates how expressive hardware and dialog software can create engaging demonstrations.</p><h3>Atlas</h3><img class="paspo" src="/atlas.png"><p>Atlas is a high-performance humanoid focused on dynamic agility, balance, and recovery.<br>It combines low-latency sensing (IMUs, joint encoders) with powerful actuators for fast motion.<br>Model-predictive and trajectory-optimization controllers enable jumps, runs, and push recovery.<br>Depth sensing and state estimation provide terrain awareness for foot-placement planning.<br>Simulation-first workflows and domain randomization reduce risk before hardware trials.<br>Thermal and battery management are engineered to support repeated high-power operations.<br>Research uses include mobility tests for search-and-rescue and uneven-terrain traversal.<br>Safety interlocks and constrained control outputs protect hardware and nearby humans during tests.<br>Atlas represents the frontier of legged and bipedal dynamic control research and demonstration.<br>Its development shows how control theory and high-bandwidth mechanics enable agile behaviors.</p><h3>Spot</h3><img class="paspo" src="/spot.png"><p>Spot is a versatile quadruped used for inspection, mapping, and remote sensing tasks.<br>It adapts gait and foothold selection for stairs, slopes, and rough terrain for reliable access.<br>Payloads commonly include LiDAR, thermal cameras, and RGB rigs for automated inspections.<br>Operation modes: teleoperation, waypoint navigation, and scripted mission sequences for repeatability.<br>Spot’s mapping output integrates with BIM or site models for deviation analysis and reporting.<br>Safety includes obstacle detection, remote stop, and recovery behaviors if tripped or stuck.<br>Industrial use-cases: construction progress scans, site health checks, and confined-space inspection.<br>Routine checks cover battery health, motor calibration, and payload mounting integrity.<br>Spot shows how legged platforms expand access compared to wheeled robots in complex sites.<br>It highlights practical mission scripting and sensor fusion for automated inspection workflows.</p><h3>Solaris</h3><img class="paspo" src="/solrs.png"><p>Solaris is a solar-powered field robot used for long-duration environmental and agricultural sensing.<br>Photovoltaic panels and an energy-aware scheduler extend operational uptime between maintenance visits.<br>Sensors include multispectral cameras, soil moisture probes, and micro-weather stations for local microclimate data.<br>Onboard edge analytics compute NDVI-like indices to detect crop stress and prioritize areas for inspection.<br>Sampling rates are duty-cycled: high-frequency sensing during peak solar input, low-power standby at night.<br>Solaris uploads batched data during high-insolation windows to conserve energy on cellular links.<br>Deployments focus on irrigation alerts, crop health mapping, and remote site monitoring with low maintenance footprint.<br>Design priorities: ruggedization, easy field servicing, and integration with farm-management systems.<br>Energy-aware behavior makes Solaris a practical example of sustainable, remote-capable robotics.<br>It demonstrates trade-offs between sensing fidelity and long-term power autonomy in the field.</p><h3>Curiosity</h3><img class="paspo" src="/curio.png"><p>Curiosity is a Mars rover that performs autonomous navigation, sampling, and on-board science analysis.<br>Navigation fuses stereo vision, visual odometry, IMU data, and wheel odometry for robust traverse planning.<br>The robotic arm contains a drill, scoop, and sample-handling mechanisms to prepare materials for instruments.<br>Autonomy includes hazard detection, path planning, and mission-sequence execution with fault protection.<br>Curiosity uses an RTG power source for long-term, sunlight-independent operation on Mars.<br>Science workflows include target imaging, sample acquisition, instrument sequencing, and data compression for downlink.<br>Robust state machines and conservative autonomy ensure survival across power and thermal cycles.<br>Long-duration maintenance focuses on software updates, wheel health monitoring, and conservative planning to reduce wear.<br>Curiosity exemplifies integrated sensing, mechanical tooling, and robust autonomy in extreme environments.<br>Its mission shows how robotics enables remote science where humans cannot operate directly.</p><h2>Other important topics in robotics</h2><p>Robotics covers many areas beyond sensors, actuators, and motion. Below are additional topics worth knowing before moving to MCQs.</p><ul><li><strong>Cybersecurity &amp; communications:</strong> secure channels (TLS, VPN), authenticated command/teleop links, and encrypted telemetry prevent spoofing or remote takeover. Network segmentation and least-privilege access are practical controls.</li><li><strong>Human–robot interaction (HRI):</strong> usability, affordances, and predictable motion patterns reduce user stress and increase trust. Simple UI cues, clear audio prompts, and transparent states (e.g., “charging”, “waiting”) help nontechnical users.</li><li><strong>Explainability &amp; logs:</strong> robots should expose concise reasons for actions (why a route was changed, why a task failed). Structured logs, traceability, and human-readable summaries speed debugging and support audits.</li><li><strong>Edge vs cloud compute:</strong> latency-sensitive perception and control stay on edge devices; heavy ML training and batch analytics run in cloud. Smart partitioning reduces round-trip delays and preserves bandwidth.</li><li><strong>Energy &amp; battery management:</strong> battery chemistry, charge cycles, and thermal limits drive duty cycles and mission length. Energy-aware software adapts sensing and communications to preserve mission-critical uptime.</li><li><strong>Modularity &amp; upgradability:</strong> modular sensor and compute bays let teams swap payloads without full redesign. Clear APIs and versioned interfaces make field upgrades and component swaps safe and predictable.</li><li><strong>Accessibility &amp; inclusion:</strong> design for diverse users (visual or hearing impairments) — tactile controls, speech alternatives, and clear visual contrast improve usability for everyone.</li><li><strong>Testing &amp; verification:</strong> unit tests for firmware, integration tests for middleware, and staged field trials prevent regressions. Hardware-in-the-loop and fault-injection tests validate safety behaviors.</li><li><strong>Supply chain &amp; maintainability:</strong> choose components with long-term availability, document spare-part lists, and design for easy field service to minimize downtime and cost.</li></ul><h2>Deployment patterns &amp; operational tips</h2><ol><li>Roll out features in gated stages: simulation → lab → small pilot → scaled deployment.</li><li>Use feature flags and remote configuration to tweak behavior without redeploying firmware.</li><li>Instrument health endpoints and heartbeat metrics; surface them on dashboards for ops teams.</li><li>Automate OTA updates with rollback paths and cryptographic signing to ensure safe upgrades.</li><li>Plan maintenance windows and keep a clear incident-runbook for common failure modes.</li></ol><h2>Regulation, standards &amp; certification</h2><p>Different industries require different compliance: medical devices, automotive, aviation, and industrial automation each have certification regimes (e.g., ISO, IEC, FDA guidance, automotive safety standards). Early engagement with regulatory requirements avoids expensive rework and ensures public safety.</p><h2>Ethics &amp; data privacy</h2><ul><li>Minimize personally identifiable data collection; anonymize and aggregate when possible.</li><li>Obtain consent for recordings and clearly communicate retention policies.</li><li>Consider bias in perception and decision models; test across representative populations.</li></ul><h2>Where to focus next (practical)</h2><ul><li>Get hands-on with a small robot: learn sensor calibration, motor tuning, and safe testing patterns.</li><li>Practice ROS basics: publish/subscribe, bag recording, and simple launch files.</li><li>Build a small data pipeline: collect sensor logs, label a few examples, run a lightweight model on edge.</li><li>Create a checklist for pre-flight / pre-deploy checks: battery, sensors, communication, E-stop test.</li></ul><h2>Conclusion</h2><p>Robotics is an engineering discipline that mixes hardware, software, and human factors. Success comes from careful system design, staged testing, robust monitoring, and attention to safety, privacy, and maintainability. With methodical practices—modularity, logging, energy-aware behavior, and clear human interfaces—robots can be reliable tools across industry, research, and public service.</p><h2>MCQs</h2><p><span>1. Which programming language is commonly used for quick prototyping and machine learning in robotics?</span></p><p>(a) Java</p><p>(b) Python</p><p>(c) C#</p><p>(d) Kotlin</p><button class="answer-btn" onclick="showBtnAnswer1()">Answer</button><p class="answer-option" id="answer1">► (b) Python</p><p><span>2. What is the main purpose of actuators in a robot?</span></p><p>(a) To sense the environment</p><p>(b) To control decision making</p><p>(c) To convert electrical signals into motion</p><p>(d) To store energy</p><button class="answer-btn" onclick="showBtnAnswer2()">Answer</button><p class="answer-option" id="answer2">► (c) To convert electrical signals into motion</p><p><span>3. Which robot is specifically designed for child-focused educational interaction?</span></p><p>(a) ASIMO</p><p>(b) Rashmi</p><p>(c) Champak</p><p>(d) Solaris</p><button class="answer-btn" onclick="showBtnAnswer3()">Answer</button><p class="answer-option" id="answer3">► (c) Champak</p><p><span>4. Which language is typically used for low-level microcontroller firmware in robotics?</span></p><p>(a) Python</p><p>(b) Embedded C</p><p>(c) JavaScript</p><p>(d) MATLAB</p><button class="answer-btn" onclick="showBtnAnswer4()">Answer</button><p class="answer-option" id="answer4">► (b) Embedded C</p><p><span>5. What is the primary function of sensors in robotics?</span></p><p>(a) Execute movement commands</p><p>(b) Collect data about the environment</p><p>(c) Control energy supply</p><p>(d) Simulate algorithms</p><button class="answer-btn" onclick="showBtnAnswer5()">Answer</button><p class="answer-option" id="answer5">► (b) Collect data about the environment</p><p><span>6. Which robot is known for expressive facial motion and social interaction?</span></p><p>(a) Atlas</p><p>(b) Sophia</p><p>(c) Spot</p><p>(d) RADA</p><button class="answer-btn" onclick="showBtnAnswer6()">Answer</button><p class="answer-option" id="answer6">► (b) Sophia</p><p><span>7. ROS (Robot Operating System) is primarily used for:</span></p><p>(a) Designing robot hardware</p><p>(b) Middleware for communication between sensors and controllers</p><p>(c) Battery management</p><p>(d) Writing web applications</p><button class="answer-btn" onclick="showBtnAnswer7()">Answer</button><p class="answer-option" id="answer7">► (b) Middleware for communication between sensors and controllers</p><p><span>8. What is a key safety feature implemented in most humanoid robots like Rashmi and Mitra?</span></p><p>(a) Facial recognition only</p><p>(b) Proximity sensors and emergency stop</p><p>(c) Random movement patterns</p><p>(d) Unlimited speed motors</p><button class="answer-btn" onclick="showBtnAnswer8()">Answer</button><p class="answer-option" id="answer8">► (b) Proximity sensors and emergency stop</p><p><span>9. Which robot is designed for dynamic agility, balance, and push recovery research?</span></p><p>(a) Atlas</p><p>(b) Curiosity</p><p>(c) Champak</p><p>(d) Solaris</p><button class="answer-btn" onclick="showBtnAnswer9()">Answer</button><p class="answer-option" id="answer9">► (a) Atlas</p><p><span>10. Which robotics topic involves designing interfaces that reduce user stress and increase trust?</span></p><p>(a) ROS programming</p><p>(b) Human–robot interaction (HRI)</p><p>(c) PID control</p><p>(d) Energy management</p><button class="answer-btn" onclick="showBtnAnswer10()">Answer</button><p class="answer-option" id="answer10">► (b) Human–robot interaction (HRI)</p><p><span>11. Spot, the quadruped robot, is primarily used for:</span></p><p>(a) Social education</p><p>(b) Mars exploration</p><p>(c) Inspection, mapping, and remote sensing</p><p>(d) Child learning</p><button class="answer-btn" onclick="showBtnAnswer11()">Answer</button><p class="answer-option" id="answer11">► (c) Inspection, mapping, and remote sensing</p><p><span>12. What is one practical reason to use Python in robotics?</span></p><p>(a) It is hardware-specific</p><p>(b) It integrates well with sensors and machine learning</p><p>(c) It cannot run on ROS</p><p>(d) It replaces all C++ code</p><button class="answer-btn" onclick="showBtnAnswer12()">Answer</button><p class="answer-option" id="answer12">► (b) It integrates well with sensors and machine learning</p><p><span>13. Which robot collects environmental data using solar power and sensors in agriculture?</span></p><p>(a) ASIMO</p><p>(b) Solaris</p><p>(c) Rashmi</p><p>(d) Atlas</p><button class="answer-btn" onclick="showBtnAnswer13()">Answer</button><p class="answer-option" id="answer13">► (b) Solaris</p><p><span>14. What is an important practice when deploying robots in real environments?</span></p><p>(a) Directly deploying without simulation</p><p>(b) Rolling out features in gated stages (simulation → lab → pilot → full deployment)</p><p>(c) Avoid testing</p><p>(d) Using unverified firmware updates</p><button class="answer-btn" onclick="showBtnAnswer14()">Answer</button><p class="answer-option" id="answer14">► (b) Rolling out features in gated stages (simulation → lab → pilot → full deployment)</p><p><span>15. Which robot performs autonomous navigation and science analysis on Mars?</span></p><p>(a) Spot</p><p>(b) Curiosity</p><p>(c) Champak</p><p>(d) RADA</p><button class="answer-btn" onclick="showBtnAnswer15()">Answer</button><p class="answer-option" id="answer15">► (b) Curiosity</p><p><span>16. Why is energy-aware software important in robotics?</span></p><p>(a) To increase maximum speed</p><p>(b) To optimize battery life and mission-critical uptime</p><p>(c) To replace sensors</p><p>(d) To avoid programming errors</p><button class="answer-btn" onclick="showBtnAnswer16()">Answer</button><p class="answer-option" id="answer16">► (b) To optimize battery life and mission-critical uptime</p><p><span>17. In ROS2, a “publisher” node is used to:</span></p><p>(a) Control motor speed directly</p><p>(b) Send sensor data to other nodes</p><p>(c) Store energy</p><p>(d) Visualize images</p><button class="answer-btn" onclick="showBtnAnswer17()">Answer</button><p class="answer-option" id="answer17">► (b) Send sensor data to other nodes</p><p><span>18. What is the primary goal of modular and upgradable robot design?</span></p><p>(a) To prevent software updates</p><p>(b) To allow swapping components without full redesign</p><p>(c) To restrict sensor integration</p><p>(d) To avoid energy management</p><button class="answer-btn" onclick="showBtnAnswer18()">Answer</button><p class="answer-option" id="answer18">► (b) To allow swapping components without full redesign</p></section><footer class="tern-footer"><div class="footer-container"><div class="footer-column logo-quote-col"><div class="footer-logo"><img alt="Wabne Logo" src="/favicon.gif"> <span>Wabne</span></div><p class="footer-quote">"The beautiful thing about learning is nobody can take it away from you." – B.B. King</p></div><div class="footer-column landscapely"><h3>Quick Links</h3><ul><li><a href="/#home">Home</a></li><li><a href="/#courses">Courses</a></li><li><a href="/#about-us">About Us</a></li><li><a href="/knomau/">Know More About Us</a></li></ul></div><div class="footer-column landscapely"><h3>Class 6<sup>th</sup></h3><ul><li><a href="/sixth/#s1">Maths</a></li><li><a href="/sixth/#s2">Science</a></li><li><a href="/sixth/#s3">Social Science</a></li><li><a href="/sixth/#s4">Computer Science</a></li></ul></div><div class="footer-column landscapely"><h3>Class 7<sup>th</sup></h3><ul><li><a href="/seventh/#s1">Maths</a></li><li><a href="/seventh/#s2">Science</a></li><li><a href="/seventh/#s3">Social Science</a></li><li><a href="/seventh/#s4">Computer Science</a></li></ul></div><div class="footer-column landscapely"><h3>Class 8<sup>th</sup></h3><ul><li><a href="/eighth/#s1">Maths</a></li><li><a href="/eighth/#s2">Science</a></li><li><a href="/eighth/#s3">Social Science</a></li><li><a href="/eighth/#s4">Computer Science</a></li></ul></div></div><div class="Maha-division portraitly"><div class="footer-column"><h3>Quick Links</h3><ul><li><a href="/#home">Home</a></li><li><a href="/#courses">Courses</a></li><li><a href="/#about-us">About Us</a></li><li><a href="/knomau/">Know More About Us</a></li></ul></div><div class="footer-column"><h3>Class 6<sup>th</sup></h3><ul><li><a href="/sixth/#s1">Maths</a></li><li><a href="/sixth/#s2">Science</a></li><li><a href="/sixth/#s3">Social Science</a></li><li><a href="/sixth/#s4">Computer Science</a></li></ul></div></div><div class="Maha-division portraitly"><div class="footer-column"><h3>Class 7<sup>th</sup></h3><ul><li><a href="/seventh/#s1">Maths</a></li><li><a href="/seventh/#s2">Science</a></li><li><a href="/seventh/#s3">Social Science</a></li><li><a href="/seventh/#s4">Computer Science</a></li></ul></div><div class="footer-column"><h3>Class 8<sup>th</sup></h3><ul><li><a href="/eighth/#s1">Maths</a></li><li><a href="/eighth/#s2">Science</a></li><li><a href="/eighth/#s3">Social Science</a></li><li><a href="/eighth/#s4">Computer Science</a></li></ul></div></div><div class="footer-bottom">© 2025 Wabne. All rights reserved.</div></footer></html>